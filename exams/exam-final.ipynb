{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda9ed85-f249-4aee-97e7-e13c9bf0d6c8",
   "metadata": {},
   "source": [
    "# Final Exam (18 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3887a4-b31b-4044-b388-b09cb7c85ed4",
   "metadata": {},
   "source": [
    "Consider the following task from [Steinmetz et al. (2019)](https://www.nature.com/articles/s41586-019-1787-x): For a repeated series of trials, a mouse is trained to rotate a wheel to indicate whether it perceives a Gabor pattern to the left or right. Spike rates from many cortical neurons are recorded on each trial. The goal is to build a model that can predict the mouse's choice based on the spiking of its cortical neurons.\n",
    "\n",
    "![](images/gabor.png)\n",
    "\n",
    "The data:\n",
    "\n",
    "* `choices`: mouse chooses whether a Gabor stimulus is to the left or right (0 or 1) on each of 276 trials \n",
    "* `spikes`: normalized spike rates for each of 691 neurons across the cortex recorded with Neuropixel probes on each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bdf4c3-548b-40d9-ba0e-280727022a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data are in the same GitHub folder as this exam notebook.\n",
    "# These files are also exactly the same as those used for the lecture examples.\n",
    "spikes = np.load('mouse_cortical_spiking.npy')\n",
    "choices = np.load('mouse_left_right_choices.npy')\n",
    "\n",
    "# If you have any issues loading the .npy files above,\n",
    "# you can try loading the data as text files instead.\n",
    "# spikes = np.loadtxt('mouse_cortical_spiking.txt')\n",
    "# choices = np.loadtxt('mouse_left_right_choices.txt')\n",
    "\n",
    "spikes.shape, choices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7053edcf-f319-41ba-89a9-e61ae06b6414",
   "metadata": {},
   "source": [
    "---\n",
    "1. (3 pts) Split the data into training and testing sets. Make sure to shuffle the data when splitting. Place 20% of the data in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931bcc8a-e0f6-4c11-95be-c6e1f7fcaf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc38ad0-59a6-477d-b77c-f4e30c4556fa",
   "metadata": {},
   "source": [
    "---\n",
    "2. (3 pts) Use stratified 10-fold cross validation to select the amount of L2 regularization to include in a logistic regression model for predicting the mouse's choice based on its neural activity. Use accuracy as the scoring metric for ranking models and only use your training dataset for this hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34f25e-c3de-4e6d-be57-b1879c89ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "model = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "param_grid = {'C': np.logspace(-3, 3, 60)}\n",
    "\n",
    "# search for the best L2 regularization hyperparameter C\n",
    "\n",
    "...\n",
    "\n",
    "# model with tuned L2 regularization hyperparameter C\n",
    "model = ...\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e32839e-d117-4e3b-92a1-5d5c4640f158",
   "metadata": {},
   "source": [
    "---\n",
    "3. (3 pts) Evaluate the selected model's accuracy on the witheld test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd33e66-8217-4abc-ac4f-1326804693a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71466c7-531b-485b-bc54-e1d97e906fc2",
   "metadata": {},
   "source": [
    "---\n",
    "4. (3 pts) Find the indices of the ten neurons that contribute the most and also the 10 neurons that contribute the least to the model's predictions. *Hint:* The contribution of each neuron is the amplitude (positive or negative) of its associated weight in the model. *Hint:* See `np.argsort`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17146d-bd07-422a-9622-a0215de8ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this reduces the model weights to a one-dimensional array\n",
    "weights = np.squeeze(model.coef_)\n",
    "\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b7145a-6b14-4ed4-a0ce-0e5ee6b63f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "top10 = ...\n",
    "bot10 = ...\n",
    "\n",
    "print(f\"Indices of neurons contributing most: {top10}\")\n",
    "print(f\"Indices of neurons contributing least: {bot10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161b92cc-c49f-4d15-8b29-be2dca056f12",
   "metadata": {},
   "source": [
    "---\n",
    "5. (3 pts) Generate two new logistic regression model's for predicting the mouse's choice based on the neural activity in ONLY the ten neurons contributing either the most or the least to the prior model's predictions as identified above. For each of these model's you will need to retune the  L2 regularization penalty using the same strategy as in question #2 above (make sure you only use your training dataset). Then evaluate the accuracy of both models on the witheld test dataset and compare to the accuracy of the model trained on all 691 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9ea6a-ca14-446d-b072-3aab0b4ce44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a2a9639-9487-4fca-b1e3-2f0569c8eff3",
   "metadata": {},
   "source": [
    "---\n",
    "6. (3 pts) **I hope that you got a lot out of this course, and that it has provided you with a basic set of tools and understanding that will be a starting point enabling you to dive into the analsis of many different types of data.** Please tell me at least one thing you liked about the course and also one aspect that needs improving. Suggestions welcome!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891f634e-09b7-45c1-b902-c36b97b18836",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
